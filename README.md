# ğŸ¤– BrowserAuto - Multi-Agent Computer Control System
<img width="1919" height="907" alt="image" src="https://github.com/user-attachments/assets/8863b99f-0f31-4f14-9122-7565353ea0ee" />



[![Python 3.13](https://img.shields.io/badge/Python-3.13-blue.svg)](https://www.python.org/)

[![Django 5.2.8](https://img.shields.io/badge/Django-5.2.8-green.svg)](https://www.djangoproject.com/)

[![LangChain](https://img.shields.io/badge/LangChain-Powered-orange.svg)](https://python.langchain.com/)[![Python 3.13](https://img.shields.io/badge/Python-3.13-blue.svg)](https://www.python.org/)

[![License](https://img.shields.io/badge/License-Educational-lightgrey.svg)]()

[![Django 5.2.8](https://img.shields.io/badge/Django-5.2.8-green.svg)](https://www.djangoproject.com/)

> An intelligent automation system that can **SEE, THINK, and ACT** on your computer using a multi-agent swarm architecture powered by Google Gemini AI.

[![LangChain](https://img.shields.io/badge/LangChain-Powered-orange.svg)](https://python.langchain.com/)An intelligent automation system that can **SEE, THINK, and ACT** on your computer using a multi-agent swarm architecture powered by Google Gemini AI.A Django-based chat application using LangGraph Swarm for multi-agent AI conversations with Gemini.

![BrowserAuto Demo](https://img.shields.io/badge/Status-Active-success)

[![License](https://img.shields.io/badge/License-Educational-lightgrey.svg)]()

---



## ğŸ“‹ Table of Contents

> An intelligent automation system that can **SEE, THINK, and ACT** on your computer using a multi-agent swarm architecture powered by Google Gemini AI.

- [Overview](#-overview)

- [Key Features](#-key-features)## ğŸŒŸ Overview## Project Structure

- [Technology Stack](#-technology-stack)

- [Architecture](#-architecture)![BrowserAuto Demo](https://img.shields.io/badge/Status-Active-success)

- [Core Tools](#-core-tools)

- [Installation](#-installation)

- [Usage](#-usage)

- [Configuration](#-configuration)---

- [Testing](#-testing)

- [Project Structure](#-project-structure)BrowserAuto is an advanced computer automation system that uses AI agents to control your computer through natural language commands. The system can see your screen, understand what's happening, and perform actions just like a human would.```

- [Troubleshooting](#-troubleshooting)

- [Key Advantages](#-key-advantages)## ğŸ“‹ Table of Contents

- [Learning Resources](#-learning-resources)

- [Contributing](#-contributing)browserauto/

- [Credits](#-credits)

- [Overview](#-overview)

---

- [Features](#-key-features)**Key Features:**â”œâ”€â”€ core/

## ğŸŒŸ Overview

- [Technology Stack](#ï¸-technology-stack)

**BrowserAuto** is an advanced computer automation system that uses AI agents to control your computer through natural language commands. The system can see your screen, understand what's happening, and perform actions just like a human would.

- [Architecture](#ï¸-architecture)- ğŸ‘ï¸ **Vision System**: Captures and analyzes screen content in real-timeâ”‚   â”œâ”€â”€ agents.py          # Agent initialization and swarm configuration

---

- [Installation](#-installation)

## ğŸ’¡ Key Features

- [Usage](#-usage)- ğŸ§  **Multi-Agent Intelligence**: 4 specialized agents working togetherâ”‚   â”œâ”€â”€ tools.py           # Tools available to agents (add, subtract, multiply)

<table>

<tr>- [Configuration](#ï¸-configuration)

<td><strong>ğŸ‘ï¸ Vision System</strong></td>

<td>Captures and analyzes screen content in real-time</td>- [Testing](#-testing)- âš¡ **Universal Control**: Works with ANY application (Chrome, Excel, Notepad, etc.)â”‚   â”œâ”€â”€ prompts.py         # Agent prompts and personalities

</tr>

<tr>- [Troubleshooting](#-troubleshooting)

<td><strong>ğŸ§  Multi-Agent Intelligence</strong></td>

<td>4 specialized agents working together</td>- [Contributing](#-contributing)- ğŸ¯ **Natural Language**: Just tell it what you want in plain Englishâ”‚   â”œâ”€â”€ views.py           # Django views (API endpoint + web page)

</tr>

<tr>

<td><strong>âš¡ Universal Control</strong></td>

<td>Works with ANY application (Chrome, Excel, Notepad, etc.)</td>---- ğŸ”„ **See-Think-Act Loop**: Intelligent decision-making based on visual feedbackâ”‚   â”œâ”€â”€ urls.py            # URL routing

</tr>

<tr>

<td><strong>ğŸ¯ Natural Language</strong></td>

<td>Just tell it what you want in plain English</td>## ğŸŒŸ Overviewâ”‚   â”œâ”€â”€ templates/

</tr>

<tr>

<td><strong>ğŸ”„ See-Think-Act Loop</strong></td>

<td>Intelligent decision-making based on visual feedback</td>**BrowserAuto** is an advanced computer automation system that uses AI agents to control your computer through natural language commands. The system can see your screen, understand what's happening, and perform actions just like a human would.---â”‚   â”‚   â””â”€â”€ core/

</tr>

</table>



---### ğŸ’¡ Key Featuresâ”‚   â”‚       â””â”€â”€ index.html # Chat interface UI



## ğŸ› ï¸ Technology Stack



### Core Framework| Feature | Description |## ğŸ› ï¸ Technology Stackâ”‚   â””â”€â”€ .env               # Environment variables (GEMINI_API_KEY)



- **Python 3.13** - Modern Python for async and performance|---------|-------------|

- **Django 5.2.8** - Web framework for user interface

- **LangChain** - Agent orchestration and tool management| ğŸ‘ï¸ **Vision System** | Captures and analyzes screen content in real-time |â”œâ”€â”€ browserauto/

- **LangGraph** - Agent workflow and state management

- **LangGraph Swarm 0.2.0** - Multi-agent coordination system| ğŸ§  **Multi-Agent Intelligence** | 4 specialized agents working together |



### AI & Language Models| âš¡ **Universal Control** | Works with ANY application (Chrome, Excel, Notepad, etc.) |### **Core Framework**â”‚   â”œâ”€â”€ settings.py        # Django settings



- **Google Gemini AI** (`gemini-1.5-flash`)| ğŸ¯ **Natural Language** | Just tell it what you want in plain English |

  - Rate Limit: **1500 requests/day** (free tier)

  - Capabilities: Vision, reasoning, natural language understanding| ğŸ”„ **See-Think-Act Loop** | Intelligent decision-making based on visual feedback |- **Python 3.13** - Modern Python for async and performanceâ”‚   â””â”€â”€ urls.py            # Main URL configuration

- **LangChain Google GenAI** - Integration layer



### Computer Vision & Automation

---- **Django 5.2.8** - Web framework for user interfaceâ”œâ”€â”€ manage.py              # Django management script

- **PyAutoGUI 0.9.54** - Screen control & automation

- **OpenCV-Python 4.12.0** - Computer vision

- **Pillow (PIL) 12.0.0** - Image processing

- **NumPy 2.2.6** - Numerical operations## ğŸ› ï¸ Technology Stack- **LangChain** - Agent orchestration and tool managementâ””â”€â”€ test_agents.py         # Test script for agents



### Supporting Libraries



- **python-dotenv** - Environment management### Core Framework- **LangGraph** - Agent workflow and state management```

- **httpx** - HTTP client

- **selenium** - Browser automation (optional/legacy)



---```yaml- **LangGraph Swarm** - Multi-agent coordination system



## ğŸ—ï¸ ArchitecturePython: 3.13



### Multi-Agent Swarm SystemDjango: 5.2.8## Features



The system uses **4 specialized agents** that collaborate through a swarm architecture:LangChain: Latest



```LangGraph: Latest### **AI & Language Models**

User Request

     â†“LangGraph Swarm: 0.2.0

ğŸ¯ Coordinator Agent

  â†’ Understands request```- **Google Gemini AI** (`gemini-1.5-flash`)- **Alice**: Math expert agent with addition, subtraction, and multiplication tools

  â†’ Breaks down tasks

  â†’ Delegates work

     â†“

ğŸ“‹ TaskPlanner Agent### AI & Language Models  - Model: `ChatGoogleGenerativeAI`- **Bob**: Friendly pirate assistant for general conversations

  â†’ Creates TODO lists

  â†’ Step-by-step planning

  â†’ Task sequencing

     â†“- **Google Gemini AI** (`gemini-1.5-flash`)  - Rate Limit: 1500 requests/day (free tier)- **Agent Handoffs**: Agents can transfer conversations to each other

âš¡ Executor Agent

  â†’ ğŸ‘ï¸ SEES screen  - Rate Limit: **1500 requests/day** (free tier)

  â†’ ğŸ§  THINKS about action

  â†’ âš¡ ACTS on decision  - Capabilities: Vision, reasoning, natural language understanding  - Capabilities: Vision, reasoning, natural language understanding- **Memory**: Conversation history maintained per thread

  â†’ âœ… VERIFIES result

     â†“- **LangChain Google GenAI** - Integration layer

ğŸ“Š Reporter Agent

  â†’ Formats results- **LangChain Google GenAI** - Integration layer for Gemini- **Real-time Chat**: Interactive web interface

  â†’ Adds screenshots

  â†’ Provides evidence### Computer Vision & Automation

     â†“

User receives detailed results

```

```yaml

### Agent Roles

PyAutoGUI: 0.9.54      # Screen control & automation### **Computer Vision & Automation**## Setup

<table>

<thead>OpenCV-Python: 4.12.0  # Computer vision

<tr>

<th>Agent</th>Pillow (PIL): 12.0.0   # Image processing- **PyAutoGUI 0.9.54** - Screen control, mouse, and keyboard automation

<th>Role</th>

<th>Tools</th>NumPy: 2.2.6           # Numerical operations

</tr>

</thead>```- **OpenCV-Python 4.12.0.88** - Computer vision and image analysis1. **Install Dependencies**:

<tbody>

<tr>

<td><strong>ğŸ¯ Coordinator</strong></td>

<td>Entry point, understands requests</td>### Supporting Libraries- **Pillow (PIL) 12.0.0** - Image processing and screenshot handling   ```bash

<td>Handoff tools</td>

</tr>

<tr>

<td><strong>ğŸ“‹ TaskPlanner</strong></td>- `python-dotenv` - Environment management- **NumPy 2.2.6** - Numerical operations for screen analysis   pip install langgraph-swarm langchain-google-genai python-dotenv django

<td>Creates detailed TODO lists</td>

<td>Handoff tools</td>- `httpx` - HTTP client

</tr>

<tr>- `selenium` - Browser automation (optional/legacy)   ```

<td><strong>âš¡ Executor</strong></td>

<td>Executes with vision-action loop</td>

<td>see_screen, perform_action, mouse tools</td>

</tr>---### **Web Automation** (Optional/Legacy)

<tr>

<td><strong>ğŸ“Š Reporter</strong></td>

<td>Formats results with evidence</td>

<td>see_screen, get_mouse_position</td>## ğŸ—ï¸ Architecture- **Selenium WebDriver** - Browser automation (deprecated in favor of universal control)2. **Configure API Key**:

</tr>

</tbody>

</table>

### Multi-Agent Swarm System- **Chrome WebDriver** - Chrome-specific automation   Create `core/.env` file:

---



## ğŸ”§ Core Tools

```   ```

### 1ï¸âƒ£ Vision Tool

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

```python

see_screen(analysis_request: str) -> strâ”‚                        User Request                          â”‚### **Supporting Libraries**   GEMINI_API_KEY=your_gemini_api_key_here

```

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

**Purpose:** Captures and analyzes screen state

                      â”‚- **python-dotenv** - Environment variable management   ```

**Returns:**

- Screen resolution & mouse position                      â–¼

- Visible applications & UI elements

- Element coordinates         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”- **typing** - Type hints and annotations

- Recommendations for next action

         â”‚  ğŸ¯ Coordinator Agent  â”‚

**Example:**

```python         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚- **asyncio** - Asynchronous operations3. **Run Migrations** (optional):

see_screen("Is Chrome open?")

see_screen("Where is the profile icon?")         â”‚  â”‚ Entry point      â”‚  â”‚

see_screen("Find the address bar")

```         â”‚  â”‚ Breaks down task â”‚  â”‚- **re** (regex) - Pattern matching for command parsing   ```bash



---         â”‚  â”‚ Delegates work   â”‚  â”‚



### 2ï¸âƒ£ Action Tool         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   python manage.py migrate



```python         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

perform_action(action_description: str) -> str

```                  â”‚---   ```



**Supported Actions:**                  â–¼



<table>         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

<thead>

<tr>         â”‚  ğŸ“‹ TaskPlanner Agent  â”‚

<th>Action</th>

<th>Example</th>         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚## ğŸ—ï¸ Architecture4. **Start Server**:

</tr>

</thead>         â”‚  â”‚ Creates TODO     â”‚  â”‚

<tbody>

<tr>         â”‚  â”‚ Step-by-step     â”‚  â”‚   ```bash

<td>Open app</td>

<td><code>open chrome</code></td>         â”‚  â”‚ Sequencing       â”‚  â”‚

</tr>

<tr>         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚### **Multi-Agent Swarm System**   python manage.py runserver

<td>Click</td>

<td><code>click at coordinates 1820, 50</code></td>         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

</tr>

<tr>                  â”‚   ```

<td>Type</td>

<td><code>type 'Hello World'</code></td>                  â–¼

</tr>

<tr>         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”The system uses **4 specialized agents** that collaborate through a swarm architecture:

<td>Press keys</td>

<td><code>press ctrl+c</code></td>         â”‚   âš¡ Executor Agent    â”‚

</tr>

<tr>         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚5. **Open Browser**:

<td>Mouse move</td>

<td><code>move mouse to 500, 300</code></td>         â”‚  â”‚ ğŸ‘ï¸ SEE screen   â”‚  â”‚

</tr>

<tr>         â”‚  â”‚ ğŸ§  THINK         â”‚  â”‚```   Navigate to `http://127.0.0.1:8000/`

<td>Scroll</td>

<td><code>scroll down</code></td>         â”‚  â”‚ âš¡ ACT           â”‚  â”‚

</tr>

<tr>         â”‚  â”‚ âœ… VERIFY        â”‚  â”‚User Request

<td>Wait</td>

<td><code>wait 2 seconds</code></td>         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚

</tr>

</tbody>         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â†“## API Usage

</table>

                  â”‚

---

                  â–¼[Coordinator] â”€â”€â”€â”€â”€â”€â†’ Understands request & delegates

### 3ï¸âƒ£ Mouse Tools

         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

```python

move_mouse(x: int, y: int) -> str         â”‚   ğŸ“Š Reporter Agent    â”‚     â†“### Chat Endpoint

click_mouse(x: int, y: int) -> str

get_mouse_position() -> str         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚

```

         â”‚  â”‚ Format results   â”‚  â”‚[TaskPlanner] â”€â”€â”€â”€â”€â”€â†’ Creates detailed TODO list

- Precise mouse control

- Coordinate-based operations         â”‚  â”‚ Screenshots      â”‚  â”‚

- Real-time position tracking

         â”‚  â”‚ Evidence         â”‚  â”‚     â†“**URL**: `POST /api/chat/`

---

         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚

## ğŸ“¦ Installation

         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜[Executor] â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ SEE â†’ THINK â†’ ACT loop

### Prerequisites

                  â”‚

âœ… Python 3.13 or higher  

âœ… Windows OS                    â–¼     â†“                 â”œâ”€ see_screen() - Vision**Request**:

âœ… Google Gemini API Key ([Get one here](https://ai.google.dev/))

         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

### Quick Start

         â”‚     User receives      â”‚     â†“                 â”œâ”€ perform_action() - Action```json

```bash

# 1. Navigate to project directory         â”‚  detailed results with â”‚

cd d:\tp_project

         â”‚      screenshots       â”‚     â†“                 â””â”€ Mouse tools - Precision{

# 2. Create virtual environment

python -m venv myenv         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

myenv\Scripts\Activate.ps1

```     â†“  "message": "what's 5 + 7?",

# 3. Install dependencies

pip install -r requirements.txt



# 4. Configure API key### Agent Roles[Reporter] â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Formats results with evidence  "thread_id": "user_123"

# Create .env file in browserauto/ directory

echo GEMINI_API_KEY=your_api_key_here > browserauto\.env



# 5. Run migrations| Agent | Role | Tools |     â†“}

cd browserauto

python manage.py migrate|-------|------|-------|



# 6. Start server| **ğŸ¯ Coordinator** | Entry point, understands requests | Handoff tools |User receives results```

python manage.py runserver 8000

| **ğŸ“‹ TaskPlanner** | Creates detailed TODO lists | Handoff tools |

# 7. Open browser

# Navigate to: http://127.0.0.1:8000/| **âš¡ Executor** | Executes with vision-action loop | `see_screen`, `perform_action`, mouse tools |```

```

| **ğŸ“Š Reporter** | Formats results with evidence | `see_screen`, `get_mouse_position` |

### Manual Installation

**Response**:

```bash

pip install django==5.2.8---

pip install langchain langchain-google-genai langgraph langgraph-swarm

pip install pillow pyautogui opencv-python numpy#### **Agent Roles:**```json

pip install python-dotenv

```## ğŸ”§ Core Tools



---{



## ğŸš€ Usage### 1ï¸âƒ£ Vision Tool



### Example Commands1. **Coordinator Agent**  "success": true,



**Simple Actions:**```python

```

"Open Chrome"see_screen(analysis_request: str) -> str   - Entry point for all user requests  "response": "The answer is 12.",

"Open Notepad and type 'Hello World'"

"Open Calculator"```

```

   - Breaks down complex tasks into objectives  "active_agent": "Alice",

**Browser Automation:**

```**Purpose:** Captures and analyzes screen state

"Open Chrome with KHAYALICO profile and go to LinkedIn"

"Click on the profile icon, then select KHAYALICO"   - Delegates work to appropriate agents  "messages": [...]

```

**Returns:**

**Complex Workflows:**

```- Screen resolution & mouse position   - Tools: Handoff tools}

"Open Chrome, go to Gmail, compose a new email"

"Open Excel, create a new spreadsheet, save as 'Data.xlsx'"- Visible applications & UI elements

"Search for 'Python tutorial' on Google and open first link"

```- Element coordinates```



### How It Works- Recommendations for next action



**Example Flow:**2. **TaskPlanner Agent**



```**Example:**

Command: "Open Chrome with KHAYALICO profile and go to LinkedIn"

```python   - Creates detailed, step-by-step TODO lists## Testing

Step 1 - ğŸ¯ Coordinator

"Break down this Chrome task"see_screen("Is Chrome open?")



Step 2 - ğŸ“‹ TaskPlanner creates TODO:see_screen("Where is the profile icon?")   - Formats instructions for Executor

âœ… Check if Chrome is open

âœ… If not, open Chromesee_screen("Find the address bar")

âœ… Find profile icon (coordinates)

âœ… Click profile icon```   - Handles task breakdown and sequencingRun the test script:

âœ… Select KHAYALICO

âœ… Navigate to linkedin.com



Step 3 - âš¡ Executor executes:---   - Tools: Handoff tools```bash

ğŸ‘ï¸ see_screen("Is Chrome open?")

â†’ "Chrome not visible"



âš¡ perform_action("open chrome")### 2ï¸âƒ£ Action Toolpython test_agents.py

â†’ Chrome opens (you see it!)



ğŸ‘ï¸ see_screen("Where is profile icon?")

â†’ "Profile icon at (1820, 50)"```python3. **Executor Agent** (The Workhorse)```



âš¡ perform_action("click at 1820, 50")perform_action(action_description: str) -> str

â†’ Profile menu opens

```   - **SEES** the screen using `see_screen()`

... continues through each step ...



Step 4 - ğŸ“Š Reporter

"âœ… Success! Chrome opened with KHAYALICO, LinkedIn loaded"**Supported Actions:**   - **THINKS** about what to do next## Agents

```



---

| Action | Example |   - **ACTS** using `perform_action()`

## âš™ï¸ Configuration

|--------|---------|

### Model Selection

| Open app | `open chrome` |   - Uses mouse tools for precision### Alice (Math Expert)

Edit `core/agents.py`:

| Click | `click at coordinates 1820, 50` |

```python

model = ChatGoogleGenerativeAI(| Type | `type 'Hello World'` |   - Tools: `see_screen`, `perform_action`, `move_mouse`, `click_mouse`, `get_mouse_position`- **Tools**: add, subtract, multiply, handoff to Bob

    model="gemini-1.5-flash",  # or "gemini-2.0-flash-exp"

    api_key=api_key,| Press keys | `press ctrl+c` |

    convert_system_message_to_human=True

)| Mouse move | `move mouse to 500, 300` |- **Specialty**: Mathematical operations and problem-solving

```

| Scroll | `scroll down` |

### Rate Limits

| Wait | `wait 2 seconds` |4. **Reporter Agent**- **Prompt**: Defined in `prompts.py`

<table>

<thead>

<tr>

<th>Model</th>---   - Formats execution results

<th>Requests/Day</th>

<th>RPM</th>

</tr>

</thead>### 3ï¸âƒ£ Mouse Tools   - Provides evidence with screenshots### Bob (Pirate Assistant)

<tbody>

<tr>

<td><code>gemini-1.5-flash</code></td>

<td>1500</td>```python   - Comprehensive status reporting- **Tools**: handoff to Alice

<td>15</td>

</tr>move_mouse(x: int, y: int) -> str

<tr>

<td><code>gemini-2.0-flash-exp</code></td>click_mouse(x: int, y: int) -> str   - Tools: `see_screen`, `get_mouse_position`- **Specialty**: General conversations in pirate style

<td>50</td>

<td>5</td>get_mouse_position() -> str

</tr>

</tbody>```- **Prompt**: Defined in `prompts.py`

</table>



### Safety Settings

---### **LangGraph Swarm Features**

In `tools.py`:



```python

pyautogui.FAILSAFE = True  # Move mouse to corner to abort## ğŸ“¦ Installation## Customization

pyautogui.PAUSE = 0.5      # Delay between actions

```



---### Prerequisites- **`create_react_agent()`** - Creates ReAct (Reasoning + Acting) agents



## ğŸ”¬ Testing



### Test Scripts- âœ… Python 3.13 or higher- **`create_handoff_tool()`** - Enables agent-to-agent communication### Adding New Tools



```bash- âœ… Windows OS

# 1. Multi-agent swarm test

python test_swarm_agents.py- âœ… Google Gemini API Key ([Get one here](https://ai.google.dev/))- **`create_swarm()`** - Orchestrates multi-agent workflowsEdit `core/tools.py`:



# 2. Live demo (Chrome + KHAYALICO + LinkedIn)

python demo_live_control.py

### Quick Start- **State Management** - Maintains context across agent handoffs```python

# 3. Direct agent testing

python test_agents.py

```

```bash- **Automatic Tool Routing** - Smart tool selection per agentdef your_tool(param: type) -> return_type:

---

# 1. Navigate to project directory

## ğŸ“ Project Structure

cd d:\tp_project    """Tool description."""

```

browserauto/

â”œâ”€â”€ core/

â”‚   â”œâ”€â”€ agents.py              # Multi-agent swarm config# 2. Create virtual environment---    # Your implementation

â”‚   â”œâ”€â”€ prompts.py             # Agent role definitions

â”‚   â”œâ”€â”€ tools.py               # Vision & action toolspython -m venv myenv

â”‚   â”œâ”€â”€ views.py               # Django views

â”‚   â”œâ”€â”€ urls.py                # URL routingmyenv\Scripts\Activate.ps1    return result

â”‚   â””â”€â”€ templates/

â”‚       â””â”€â”€ core/

â”‚           â””â”€â”€ index.html     # Web interface

â”œâ”€â”€ browserauto/# 3. Install dependencies## ğŸ”§ Core Tools```

â”‚   â”œâ”€â”€ settings.py            # Django settings

â”‚   â”œâ”€â”€ urls.py                # Main URL configpip install -r requirements.txt

â”‚   â””â”€â”€ wsgi.py                # WSGI config

â”œâ”€â”€ manage.py                  # Django management

â”œâ”€â”€ requirements.txt           # Dependencies

â”œâ”€â”€ .env                       # API keys (not in repo)# 4. Configure API key

â””â”€â”€ README.md                  # This file

```# Create .env file in browserauto/ directory### **1. Vision Tool - `see_screen()`**### Modifying Prompts



---echo GEMINI_API_KEY=your_api_key_here > browserauto\.env



## ğŸ› Troubleshooting```pythonEdit `core/prompts.py`:



### API Rate Limit Exceeded# 5. Run migrations



```cd browserautosee_screen(analysis_request: str) -> str```python

Error: 429 You exceeded your current quota

```python manage.py migrate



**Solution:**```YOUR_AGENT_PROMPT = """Your custom prompt here"""

- Wait for quota reset (daily at midnight)

- Switch to `gemini-1.5-flash` (1500 req/day)# 6. Start server



### Vision System Not Availablepython manage.py runserver 8000- Captures current screen state```



```

Error: Vision system not available

```# 7. Open browser- Analyzes based on request (e.g., "Is Chrome open?", "Where is the profile icon?")



**Solution:**# Navigate to: http://127.0.0.1:8000/

```bash

pip install pillow pyautogui opencv-python numpy```- Returns detailed analysis with:### Adding New Agents

```



### Permission Errors

### Manual Installation  - Screen resolution and mouse positionEdit `core/agents.py` and add new agent configuration.

**Solution:** Run terminal as Administrator



### Actions Too Fast

```bash  - Visible applications and UI elements

**Solution:** Increase delay in `tools.py`:

```pythonpip install django==5.2.8

pyautogui.PAUSE = 1.0  # Increase from 0.5

```pip install langchain langchain-google-genai langgraph langgraph-swarm  - Coordinates of important elements## Technologies Used



---pip install pillow pyautogui opencv-python numpy



## ğŸ¯ Key Advantagespip install python-dotenv  - Recommendations for next action



### âœ… See-Think-Act Loop```



Unlike traditional automation that blindly executes commands:- **Django**: Web framework



<table>---

<thead>

<tr>**Technology:** PyAutoGUI (screenshot), OpenCV (analysis), NumPy (image processing)- **LangGraph Swarm**: Multi-agent orchestration

<th>Traditional</th>

<th>BrowserAuto</th>## ğŸš€ Usage

</tr>

</thead>- **LangChain**: Agent framework

<tbody>

<tr>### Example Commands

<td>âŒ Hardcoded clicks</td>

<td>âœ… Sees screen first</td>### **2. Action Tool - `perform_action()`**- **Google Gemini**: LLM (gemini-2.0-flash-exp)

</tr>

<tr>#### Simple Actions

<td>âŒ Blind execution</td>

<td>âœ… Thinks about context</td>``````python- **Python-dotenv**: Environment variable management

</tr>

<tr>"Open Chrome"

<td>âŒ No verification</td>

<td>âœ… Verifies each action</td>"Open Notepad and type 'Hello World'"perform_action(action_description: str) -> str

</tr>

<tr>"Open Calculator"

<td>âŒ Breaks easily</td>

<td>âœ… Adapts to changes</td>``````## Notes

</tr>

</tbody>

</table>

#### Browser Automation- Executes actions based on natural language

### âœ… Universal Control

```

Works with **ANY** application:

"Open Chrome with KHAYALICO profile and go to LinkedIn"- Supported actions:- Each conversation thread maintains its own state

- âœ… Browsers (Chrome, Firefox, Edge)

- âœ… Office (Word, Excel, PowerPoint)"Click on the profile icon, then select KHAYALICO"

- âœ… Utilities (Notepad, Calculator, File Explorer)

- âœ… Custom applications```  - `open <application>` - Launch apps- Agents automatically transfer based on user requests



### âœ… Natural Language



Instead of writing complex code:#### Complex Workflows  - `click at coordinates <x>, <y>` - Precise clicking- The system uses in-memory checkpointing (resets on server restart)

```diff

- pyautogui.click(1820, 50); time.sleep(1); pyautogui.write('KHAYALICO')```

+ "Click on profile icon and select KHAYALICO"

```"Open Chrome, go to Gmail, compose a new email"  - `type '<text>'` - Text input- For production, consider using a persistent checkpoint backend



---"Open Excel, create a new spreadsheet, save as 'Data.xlsx'"



## ğŸ“š Learning Resources"Search for 'Python tutorial' on Google and open first link"  - `press <keys>` - Keyboard shortcuts



- **LangChain:** [https://python.langchain.com/docs/](https://python.langchain.com/docs/)```  - `move mouse to <x>, <y>` - Mouse movement

- **LangGraph:** [https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)

- **Google Gemini API:** [https://ai.google.dev/docs](https://ai.google.dev/docs)  - `scroll up/down` - Scrolling

- **PyAutoGUI:** [https://pyautogui.readthedocs.io/](https://pyautogui.readthedocs.io/)

### How It Works  - `wait <seconds>` - Delays

---

- Returns execution status with screenshot evidence

## ğŸš§ Roadmap

**Example Flow:**

- [ ] OCR integration for text recognition

- [ ] Image template matching**Technology:** PyAutoGUI (automation), regex (parsing), PIL (screenshots)

- [ ] Multi-monitor support

- [ ] Voice command input```

- [ ] Automation recording & playback

- [ ] OpenAI/Claude integrationCommand: "Open Chrome with KHAYALICO profile and go to LinkedIn"### **3. Mouse Tools**

- [ ] Mobile device control (ADB)

- [ ] Scheduled tasks```python



---1. ğŸ¯ Coordinator: "Break down this Chrome task"move_mouse(x: int, y: int) -> str



## ğŸ¤ Contributingclick_mouse(x: int, y: int) -> str



Contributions welcome! Areas for improvement:2. ğŸ“‹ TaskPlanner: Creates TODO:get_mouse_position() -> str



1. ğŸ¯ Better UI element detection   âœ… Check if Chrome is open```

2. ğŸ›¡ï¸ More robust error handling

3. ğŸ”§ Additional action types   âœ… If not, open Chrome- Precise mouse control

4. âš¡ Performance optimizations

5. ğŸ“– Documentation improvements   âœ… Find profile icon (coordinates)- Coordinate-based operations



---   âœ… Click profile icon- Real-time position tracking



## ğŸ”’ Security & Privacy   âœ… Select KHAYALICO



- âœ… All processing happens **locally**   âœ… Navigate to linkedin.com**Technology:** PyAutoGUI

- âœ… Only AI requests go to Google Gemini API

- âœ… Screenshots saved **locally** (not uploaded)

- âœ… API key in `.env` (never commit to git)

- âœ… No data collection or telemetry3. âš¡ Executor executes:---



---   ğŸ‘ï¸ see_screen("Is Chrome open?")



## ğŸ™ Credits   â†’ "Chrome not visible"## ğŸ“¦ Installation



**Technologies:**   

- [LangChain Team](https://langchain.com/) - Agent framework

- [Google](https://ai.google.dev/) - Gemini AI   âš¡ perform_action("open chrome")### **Prerequisites**

- [Django Software Foundation](https://www.djangoproject.com/) - Web framework

- [PyAutoGUI Team](https://pyautogui.readthedocs.io/) - Automation library   â†’ Chrome opens (you see it!)- Python 3.13 or higher



**Version:** 1.0.0     - Windows OS (current version)

**Date:** November 2025

   ğŸ‘ï¸ see_screen("Where is profile icon?")- Google Gemini API Key

---

   â†’ "Profile icon at (1820, 50)"

## ğŸ“„ License

   ### **Setup Steps**

This project is for **educational and personal use**.

   âš¡ perform_action("click at 1820, 50")

---

   â†’ Profile menu opens1. **Clone the repository**

## ğŸ‰ Quick Start Example

   ```powershell

```bash

# Start the server   ... continues ...cd d:\tp_project

python manage.py runserver 8000

```

# Open browser: http://127.0.0.1:8000/

4. ğŸ“Š Reporter: "âœ… Success! Chrome opened with KHAYALICO, LinkedIn loaded"

# Try this command:

"Open Chrome with KHAYALICO profile and go to LinkedIn"```2. **Create virtual environment**



# Watch the magic happen! âœ¨```powershell

```

---python -m venv myenv

**What happens:**

1. **Coordinator** breaks down the taskmyenv\Scripts\Activate.ps1

2. **TaskPlanner** creates a TODO list

3. **Executor** sees your screen, thinks, and acts## âš™ï¸ Configuration```

4. **Reporter** shows you the results



---

### Model Selection3. **Install dependencies**

<div align="center">

```powershell

**ğŸ¤– Enjoy automating your computer with AI! âœ¨**

Edit `core/agents.py`:pip install django==5.2.8

[![GitHub](https://img.shields.io/badge/GitHub-Star-yellow.svg)](https://github.com)

[![Twitter](https://img.shields.io/badge/Twitter-Share-blue.svg)](https://twitter.com)pip install langchain langchain-google-genai langgraph langgraph-swarm

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Share-blue.svg)](https://linkedin.com)

```pythonpip install pillow pyautogui opencv-python numpy

</div>

model = ChatGoogleGenerativeAI(pip install python-dotenv

    model="gemini-1.5-flash",  # or "gemini-2.0-flash-exp"pip install selenium  # Optional for legacy browser automation

    api_key=api_key,```

    convert_system_message_to_human=True

)4. **Configure API Key**

```Create `.env` file in `browserauto/` directory:

```

### Rate LimitsGEMINI_API_KEY=your_api_key_here

```

| Model | Requests/Day | RPM |

|-------|--------------|-----|Get your API key: https://ai.google.dev/

| `gemini-1.5-flash` | 1500 | 15 |

| `gemini-2.0-flash-exp` | 50 | 5 |5. **Run migrations**

```powershell

### Safety Settingscd browserauto

python manage.py migrate

In `tools.py`:```



```python6. **Start the server**

pyautogui.FAILSAFE = True  # Move mouse to corner to abort```powershell

pyautogui.PAUSE = 0.5      # Delay between actionspython manage.py runserver 8000

``````



---7. **Open in browser**

```

## ğŸ”¬ Testinghttp://127.0.0.1:8000/

```

### Test Scripts

---

```bash

# 1. Multi-agent swarm test## ğŸš€ Usage

python test_swarm_agents.py

### **Example Commands**

# 2. Live demo (Chrome + KHAYALICO + LinkedIn)

python demo_live_control.py**Simple Actions:**

```

# 3. Direct agent testing"Open Chrome"

python test_agents.py"Open Notepad and type 'Hello World'"

```"Open Calculator"

```

---

**Browser Automation:**

## ğŸ“ Project Structure```

"Open Chrome with KHAYALICO profile and go to LinkedIn"

```"Open Chrome, switch to KHAYALICO profile, then navigate to linkedin.com"

browserauto/"Click on the profile icon, then select KHAYALICO"

â”œâ”€â”€ ğŸ“‚ core/```

â”‚   â”œâ”€â”€ agents.py              # Multi-agent swarm config

â”‚   â”œâ”€â”€ prompts.py             # Agent role definitions**Complex Workflows:**

â”‚   â”œâ”€â”€ tools.py               # Vision & action tools```

â”‚   â”œâ”€â”€ views.py               # Django views"Open Chrome, go to Gmail, compose a new email"

â”‚   â”œâ”€â”€ urls.py                # URL routing"Open Excel, create a new spreadsheet, and save it as 'Data.xlsx'"

â”‚   â””â”€â”€ ğŸ“‚ templates/"Search for 'Python tutorial' on Google and open the first link"

â”‚       â””â”€â”€ core/```

â”‚           â””â”€â”€ index.html     # Web interface

â”œâ”€â”€ ğŸ“‚ browserauto/### **How It Works**

â”‚   â”œâ”€â”€ settings.py            # Django settings

â”‚   â”œâ”€â”€ urls.py                # Main URL config1. **You type a command** in the web interface

â”‚   â””â”€â”€ wsgi.py                # WSGI config2. **Coordinator receives** and understands your request

â”œâ”€â”€ manage.py                  # Django management3. **TaskPlanner creates** a detailed TODO list

â”œâ”€â”€ requirements.txt           # Dependencies4. **Executor executes** using the see-think-act loop:

â”œâ”€â”€ .env                       # API keys (not in repo)   - ğŸ‘ï¸ Captures screen â†’ Analyzes what's visible

â””â”€â”€ README.md                  # This file   - ğŸ§  Thinks about next step

```   - âš¡ Performs action

   - âœ… Verifies result

---   - ğŸ”„ Repeats until done

5. **Reporter formats** the results with screenshots

## ğŸ› Troubleshooting6. **You see results** with detailed execution logs



### Issue: API Rate Limit Exceeded---



```## ğŸ”¬ Testing

Error: 429 You exceeded your current quota

```### **Test Scripts Included**



**Solution:**1. **`test_swarm_agents.py`** - Test the multi-agent swarm

- Wait for quota reset (daily at midnight)```powershell

- Switch to `gemini-1.5-flash` (1500 req/day)python test_swarm_agents.py

```

### Issue: Vision System Not Available

2. **`demo_live_control.py`** - Live demo of Chrome + KHAYALICO + LinkedIn

``````powershell

Error: Vision system not availablepython demo_live_control.py

``````



**Solution:**3. **Direct agent testing**

```bash```powershell

pip install pillow pyautogui opencv-python numpypython test_agents.py

``````



### Issue: Permission Errors---



**Solution:** Run terminal as Administrator## ğŸ“ Project Structure



### Issue: Actions Too Fast```

browserauto/

**Solution:** Increase delay in `tools.py`:â”œâ”€â”€ core/

```pythonâ”‚   â”œâ”€â”€ agents.py          # Multi-agent swarm configuration

pyautogui.PAUSE = 1.0  # Increase from 0.5â”‚   â”œâ”€â”€ prompts.py         # Agent role definitions

```â”‚   â”œâ”€â”€ tools.py           # Vision & action tools

â”‚   â”œâ”€â”€ views.py           # Django views

---â”‚   â”œâ”€â”€ urls.py            # URL routing

â”‚   â””â”€â”€ templates/

## ğŸ¯ Key Advantagesâ”‚       â””â”€â”€ core/

â”‚           â””â”€â”€ index.html # Web interface

### âœ… See-Think-Act Loopâ”œâ”€â”€ browserauto/

Unlike traditional automation that blindly executes commands:â”‚   â”œâ”€â”€ settings.py        # Django settings

â”‚   â”œâ”€â”€ urls.py            # Main URL config

| Traditional | BrowserAuto |â”‚   â””â”€â”€ wsgi.py            # WSGI config

|-------------|-------------|â”œâ”€â”€ manage.py              # Django management

| âŒ Hardcoded clicks | âœ… Sees screen first |â”œâ”€â”€ db.sqlite3             # Database

| âŒ Blind execution | âœ… Thinks about context |â”œâ”€â”€ .env                   # API keys (not in repo)

| âŒ No verification | âœ… Verifies each action |â””â”€â”€ README.md              # This file

| âŒ Breaks easily | âœ… Adapts to changes |

myenv/                     # Virtual environment

### âœ… Universal Controlâ””â”€â”€ ...



Works with **ANY** application:Documentation/

â”œâ”€â”€ QUICKSTART.md

- âœ… Browsers (Chrome, Firefox, Edge)â”œâ”€â”€ MULTI_AGENT_SWARM.md

- âœ… Office (Word, Excel, PowerPoint)â”œâ”€â”€ AGENTS_UPGRADE_SUMMARY.md

- âœ… Utilities (Notepad, Calculator, File Explorer)â””â”€â”€ ...

- âœ… Custom applications```



### âœ… Natural Language---



```diff## ğŸ¯ Key Features Explained

- pyautogui.click(1820, 50); time.sleep(1); pyautogui.write('KHAYALICO')

+ "Click on profile icon and select KHAYALICO"### **1. See-Think-Act Loop**

```Unlike traditional automation that blindly executes commands, BrowserAuto:

- **Sees** what's actually on screen

---- **Thinks** about the current state

- **Acts** based on visual analysis

## ğŸ“š Learning Resources- **Verifies** each action succeeded



- **LangChain:** https://python.langchain.com/docs/### **2. Universal Control**

- **LangGraph:** https://langchain-ai.github.io/langgraph/Not limited to browsers! Can control:

- **Google Gemini API:** https://ai.google.dev/docs- âœ… Chrome, Firefox, Edge

- **PyAutoGUI:** https://pyautogui.readthedocs.io/- âœ… Notepad, Word, Excel

- âœ… Calculator, File Explorer

---- âœ… Any Windows application



## ğŸš§ Roadmap### **3. Natural Language**

No coding required. Just describe what you want:

- [ ] OCR integration for text recognition- âŒ Bad: `pyautogui.click(1820, 50); time.sleep(1)`

- [ ] Image template matching- âœ… Good: `"Click on the profile icon"`

- [ ] Multi-monitor support

- [ ] Voice command input### **4. Visual Feedback**

- [ ] Automation recording & playback- All actions happen visibly on your screen

- [ ] OpenAI/Claude integration- Screenshots saved for verification

- [ ] Mobile device control (ADB)- Real-time status updates

- [ ] Scheduled tasks- You see exactly what the agent is doing



---### **5. Intelligent Error Handling**

- If action fails, agent uses vision to diagnose

## ğŸ¤ Contributing- Tries alternative approaches

- Reports detailed error information

Contributions welcome! Areas for improvement:

---

1. ğŸ¯ Better UI element detection

2. ğŸ›¡ï¸ More robust error handling## âš™ï¸ Configuration

3. ğŸ”§ Additional action types

4. âš¡ Performance optimizations### **Model Selection**

5. ğŸ“– Documentation improvementsEdit `core/agents.py` to change AI model:

```python

---model = ChatGoogleGenerativeAI(

    model="gemini-1.5-flash",  # Options: gemini-1.5-flash, gemini-2.0-flash-exp

## ğŸ”’ Security & Privacy    api_key=api_key,

    convert_system_message_to_human=True

- âœ… All processing happens **locally**)

- âœ… Only AI requests go to Google Gemini API```

- âœ… Screenshots saved **locally** (not uploaded)

- âœ… API key in `.env` (never commit to git)### **Rate Limits**

- âœ… No data collection or telemetry- **gemini-1.5-flash**: 1500 requests/day (free)

- **gemini-2.0-flash-exp**: 50 requests/day (free)

---

### **Safety Settings**

## ğŸ™ CreditsPyAutoGUI safety features (in `tools.py`):

```python

**Technologies:**pyautogui.FAILSAFE = True  # Move mouse to corner to abort

- [LangChain Team](https://langchain.com/) - Agent frameworkpyautogui.PAUSE = 0.5      # Delay between actions

- [Google](https://ai.google.dev/) - Gemini AI```

- [Django Software Foundation](https://www.djangoproject.com/) - Web framework

- [PyAutoGUI Team](https://pyautogui.readthedocs.io/) - Automation library---



**Version:** 1.0.0  ## ğŸ› Troubleshooting

**Date:** November 2025

### **API Rate Limit Exceeded**

---```

Error: 429 You exceeded your current quota

## ğŸ“„ License```

**Solution:** Wait for reset or switch to `gemini-1.5-flash` in `agents.py`

This project is for **educational and personal use**.

### **Vision System Not Available**

---```

Error: Vision system not available

## ğŸ‰ Quick Start Example```

**Solution:** Install missing packages:

```bash```powershell

# Start the serverpip install pillow pyautogui opencv-python numpy

python manage.py runserver 8000```



# Open browser: http://127.0.0.1:8000/### **Permission Errors**

Some actions may require administrator privileges.

# Try this command:**Solution:** Run terminal as Administrator

"Open Chrome with KHAYALICO profile and go to LinkedIn"

### **Actions Too Fast**

# Watch the magic happen! âœ¨Increase delay in `tools.py`:

# 1. Coordinator breaks down the task```python

# 2. TaskPlanner creates a TODO listpyautogui.PAUSE = 1.0  # Increase from 0.5 to 1.0

# 3. Executor sees your screen, thinks, and acts```

# 4. Reporter shows you the results

```---



---## ğŸ”’ Security & Privacy



<div align="center">- All processing happens **locally** on your machine

- Only AI requests go to Google Gemini API

**ğŸ¤– Enjoy automating your computer with AI! âœ¨**- Screenshots are saved locally (not uploaded)

- API key stored in `.env` file (never commit to git)

[![GitHub](https://img.shields.io/badge/GitHub-Star-yellow.svg)](https://github.com)- No data collection or telemetry

[![Twitter](https://img.shields.io/badge/Twitter-Share-blue.svg)](https://twitter.com)

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Share-blue.svg)](https://linkedin.com)---



</div>## ğŸ“š LangChain & LangGraph Concepts


### **ReAct Agents**
- **Re**asoning + **Act**ing pattern
- Agent thinks before each action
- Uses chain-of-thought prompting
- Function: `create_react_agent(model, tools, prompt)`

### **Agent Swarm**
- Multiple agents working together
- Each agent has specialized role
- Agents can hand off to each other
- Maintains shared state across handoffs

### **Tool System**
- Python functions decorated with `@tool`
- Type-annotated for LangChain
- Automatic schema generation
- Built-in error handling

---

## ğŸ“ Learning Resources

### **LangChain Documentation**
- https://python.langchain.com/docs/

### **LangGraph Documentation**
- https://langchain-ai.github.io/langgraph/

### **Google Gemini API**
- https://ai.google.dev/docs

### **PyAutoGUI Documentation**
- https://pyautogui.readthedocs.io/

---

## ğŸš§ Future Enhancements

- [ ] OCR integration for text recognition
- [ ] Image template matching for UI element detection
- [ ] Multi-monitor support
- [ ] Voice command input
- [ ] Recording and playback of automation sequences
- [ ] Integration with more AI models (OpenAI, Claude)
- [ ] Mobile device control via ADB
- [ ] Scheduled automation tasks

---

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- Better UI element detection
- More robust error handling
- Additional action types
- Performance optimizations
- Documentation improvements

---

## ğŸ“„ License

This project is for educational and personal use.

---

## ğŸ™ Credits

**Technologies:**
- LangChain Team - Agent framework
- Google - Gemini AI
- Django Software Foundation - Web framework
- PyAutoGUI Team - Automation library

**Created by:** Your Name
**Date:** November 2025
**Version:** 1.0.0

---

## ğŸ“ Support

For issues or questions:
1. Check the troubleshooting section
2. Review the documentation files
3. Test with simple commands first
4. Ensure API key is valid

---

## ğŸ‰ Quick Start Example

```python
# After starting the server, try this in the web interface:
"Open Chrome with KHAYALICO profile and go to LinkedIn"

# What happens:
# 1. Coordinator: "I need to open Chrome with a specific profile"
# 2. TaskPlanner: Creates TODO:
#    - Check if Chrome is open
#    - If not, open Chrome
#    - Find profile icon
#    - Click profile icon
#    - Select KHAYALICO
#    - Navigate to linkedin.com
# 3. Executor: Executes each step with vision:
#    ğŸ‘ï¸ see_screen("Is Chrome open?")
#    âš¡ perform_action("open chrome")
#    ğŸ‘ï¸ see_screen("Where is profile icon?")
#    âš¡ perform_action("click at coordinates 1820, 50")
#    # ... continues until done
# 4. Reporter: "âœ… Successfully opened Chrome with KHAYALICO and loaded LinkedIn"
```

---

**Enjoy automating your computer with AI! ğŸ¤–âœ¨**
